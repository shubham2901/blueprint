# Blueprint — Founder Tasks

Tasks that are on the founder (not the coding agent). These must be completed before or alongside coding. The coding agent will wire functions and schemas — but the actual content below comes from you.

---

## Prompt Writing

These prompts are the brain of the product. The coding agent implements the function signatures in `backend/app/prompts.py` and wires them to the pipeline. You write the actual prompt text.

### 1. ~~Classify Prompt~~ DONE

**Status**: Written and stored in `MODULE_SPEC.md` Section 7 (`build_classify_prompt`).

Covers: intent classification (5 types), domain extraction (with reference hierarchy), multi-question clarification generation, quick responses for small_talk/off_topic. Tonality excluded intentionally — handled by the persona system prompt in `config.py`.

**Schema note**: LLM outputs `text` for question label and options as `{label, description}` (no IDs). Backend maps `text` → `label` post-parse. Selections tracked by label strings (e.g., `["Mobile", "Web"]`).

---

### 2. Gap Analysis Prompt (CRITICAL — blocks build intent completion)

**Function**: `build_gap_analysis_prompt(profiles: list[dict], clarification_context: dict) -> list[dict]`

**What it does**: Takes all competitor profiles and the user's clarification context, and synthesizes market gaps.

**Expected output schema**: `GapAnalysis` (see `MODULE_SPEC.md` Section 2)

**What to specify in the prompt**:
- How to identify "gaps" — underserved needs, unserved market segments, recurring user complaints
- How to score opportunity size (high/medium/low) — what makes a gap "high"?
- How many gaps to identify (3-6)
- How to use the clarification context to prioritize relevant gaps
- How to extract evidence from competitor profiles (not fabricate)
- How to generate actionable, specific gap titles (not vague)

---

### 3. Problem Statement Prompt (blocks build intent final step)

**Function**: `build_problem_statement_prompt(selected_gaps: list[dict], context: dict) -> list[dict]`

**What it does**: Takes user-selected gaps + research context, generates a focused problem statement.

**Expected output schema**: `ProblemStatement` (see `MODULE_SPEC.md` Section 2)

**What to specify in the prompt**:
- What makes a good problem statement (specific, actionable, grounded in evidence)
- How to synthesize multiple gaps into one coherent statement
- What "target_user" should look like (persona, not demographic)
- What "key_differentiators" should feel like (product-level, not feature-level)
- What "validation_questions" are for (questions the founder should answer before building)

---

### 4. Quick Response Templates (nice to have)

For `small_talk` and `off_topic` intents. These can be LLM-generated or hardcoded:

- "How are you?" → "I'm Blueprint, a product research assistant. Tell me what you'd like to build or explore."
- "What's the weather?" → "I focus on product and market research. What product or space would you like to explore?"
- "Hello" → "Hello! I'm here to help with product research. What would you like to build or explore?"

**Decision needed**: Should these be hardcoded in `prompts.py` or generated by the LLM each time? (Recommendation: hardcoded — cheaper, faster, more predictable.)

---

### 5. Persona System Prompt (review/refine)

**Location**: `LLM_CONFIG["persona"]["system_prompt"]` in `config.py`

Current draft:
```
You are Blueprint, a product research assistant. You help product managers
and founders understand competitive landscapes. Be concise, structured,
and always cite sources. Use bullet points for features and comparisons.
Never fabricate data — if unsure, say so.
```

**Review points**:
- Is the tone right?
- Should it mention that it does intent classification?
- Should it be more specific about structured JSON output?
- Any personality traits to add or remove?

---

## API Keys and Infrastructure

### API Keys to Obtain

| Service | Key Name | Where to Get | Env Var | Priority |
|---------|----------|-------------|---------|----------|
| Gemini | API Key | [Google AI Studio](https://aistudio.google.com/) | `GEMINI_API_KEY` | **Required** |
| Serper | API Key | [Serper.dev](https://serper.dev/) | `SERPER_API_KEY` | **Required** |
| OpenAI | API Key | [OpenAI Platform](https://platform.openai.com/) | `OPENAI_API_KEY` | Recommended (fallback) |
| Anthropic | API Key | [Anthropic Console](https://console.anthropic.com/) | `ANTHROPIC_API_KEY` | Recommended (fallback) |
| Jina | API Key | [Jina AI](https://jina.ai/) | `JINA_API_KEY` | Optional (works without, lower rate) |

**Serper setup**:
1. Go to [serper.dev](https://serper.dev/) → create an account
2. Copy the API key from the dashboard
3. Free tier: 2,500 queries/month. Paid plans scale as needed.

### Infrastructure to Set Up

| Service | What to Do | Status |
|---------|-----------|--------|
| Supabase | Create project → get URL + service role key | Pending |
| Supabase SQL | Run the schema SQL from `PLAN.md` Part 5 in the SQL editor | Pending (after schema is finalized) |
| Railway | Create project with 2 services (frontend, backend) | Pending |
| Railway Env Vars | Configure all env vars from `PLAN.md` Part 7 | Pending (after API keys obtained) |
| Domain | Optional: configure custom domain on Railway | Later |

---

## Content and Configuration

### Landing Page Copy
- Heading: "What would you like to research?" (or suggest alternative)
- Subheading / description text
- Placeholder text for the prompt input

### Suggested Research Pills
The landing page shows clickable pill/chip suggestions below the prompt input. Define the labels:

Current suggestions (adjust as needed):
- "Market Analysis"
- "Competitor Research"
- "Product Deep Dive"
- "Build something new"
- "Explore a space"

### AlternativeTo Seed Script (after backend deployment)

After the backend is deployed and the `alternatives_cache` table exists in Supabase, run the seed script:

```bash
cd backend
python -m app.seed_alternatives
```

This scrapes popular products from `alternativeto.net` and `get.alternative.to` and stores them in the `alternatives_cache` table. Should be run once, then periodically (monthly) to refresh data.

**Expected output**: Summary of how many products and alternatives were seeded per category.

### Supplementary Data Sources (V1 Planning)
Define which forums/platforms to integrate in V1:
- Product Hunt
- Hacker News (Show HN posts, discussions)
- App Store (iOS) — if V0-EXPERIMENTAL scrapers prove unreliable
- Play Store (Android) — if V0-EXPERIMENTAL scrapers prove unreliable
- Others? (Capterra, TrustRadius, etc.)

Note: G2 has been dropped (requires sign-in, aggressive anti-scraping). AlternativeTo replaces it as the primary curated-alternatives source.

---

## Priority Order

1. ~~**Classify prompt**~~ DONE.
2. **API keys** (Gemini, Serper) — needed for any backend testing.
3. **Supabase project** — needed for any DB-backed testing.
4. **Gap analysis prompt** — blocks the build intent completion.
5. **Problem statement prompt** — blocks the final build intent step.
6. **Quick response templates** — low effort, can be done anytime.
7. **Persona review** — refine after seeing the product in action.
8. **Landing page copy + pills** — needed for frontend polish.
9. **Railway setup** — needed for deployment, not for local development.
10. **Run AlternativeTo seed script** — after backend deployment + Supabase schema setup.
